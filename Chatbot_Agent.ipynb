{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:26:36.543026Z","iopub.status.idle":"2025-04-11T01:26:36.543479Z","shell.execute_reply":"2025-04-11T01:26:36.543276Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nBuilding a Customer Support Agent Foundation with Gemini\n\n**Use Case / Problem:**\n\nBusinesses need effective customer support that is responsive, accurate, and\navailable. Traditional methods face challenges:\n- Human agents can be costly and have limited working hours.\n- Basic rule-based chatbots lack natural conversation skills and cannot handle\n  complex or unforeseen queries.\n- Support agents often need access to real-time data (like order status or\n  product availability) which simple bots cannot retrieve.\n- Analyzing and routing customer requests efficiently can be time-consuming.\n\n**How Generative AI (Gemini) Can Solve This:**\n\nLarge Language Models like Google's Gemini offer powerful capabilities to\naddress these challenges:\n1.  **Natural Language Understanding:** They can understand customer queries phrased\n    in everyday language.\n2.  **Persona & Tone Control (Few-Shot Prompting):** We can guide the AI to adopt\n    a specific persona (e.g., a helpful agent for a particular brand) and\n    response style by providing examples.\n3.  **Accessing External Tools (Function Calling):** The AI can be empowered to\n    use external functions or APIs to fetch real-time data (like checking an\n    order database) or perform actions.\n4.  **Structured Data Generation (JSON Mode):** The AI can output information\n    in a structured format (like JSON) for easier processing, logging, or\n    routing by other systems.\n\n**Goal of this Notebook:**\n\nThis notebook demonstrates how to use the Google Gemini API and Python to\nbuild the foundational components of a customer support agent. We will showcase\n\n**three key Gen AI capabilities:**\n* Few-Shot Prompting (for persona)\n* Function Calling (for data retrieval)\n* Structured Output (for request categorization)\n","metadata":{}},{"cell_type":"markdown","source":"### 1. Setup: Install Libraries, Configure API Key (from Kaggle Secrets), and Define Mock Tools\n","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n\n!pip install -U -q \"google-genai==1.7.0\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:26:36.545049Z","iopub.status.idle":"2025-04-11T01:26:36.545566Z","shell.execute_reply":"2025-04-11T01:26:36.545375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai\nimport os\nimport json\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:26:55.811408Z","iopub.execute_input":"2025-04-11T01:26:55.811752Z","iopub.status.idle":"2025-04-11T01:26:55.818894Z","shell.execute_reply.started":"2025-04-11T01:26:55.811725Z","shell.execute_reply":"2025-04-11T01:26:55.817340Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'0.8.3'"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"**Import Kaggle Secrets client and retrieve the API key**","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:26:58.350600Z","iopub.execute_input":"2025-04-11T01:26:58.350993Z","iopub.status.idle":"2025-04-11T01:26:58.499108Z","shell.execute_reply.started":"2025-04-11T01:26:58.350959Z","shell.execute_reply":"2025-04-11T01:26:58.498064Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"# --- Mock Functions ---\n\nDefine mock (simulated) functions for demonstration purposes. In a real application, the support agent needs to interact with external systems (databases, APIs). These mock functions simulate that interaction, allowing us to test the Function Calling capability without needing actual databases set up for this demo.\n","metadata":{}},{"cell_type":"code","source":"def get_order_status(order_id: str) -> dict:\n    \"\"\"MOCK FUNCTION: Simulates looking up order status.\"\"\"\n    print(f\"--- MOCK FUNCTION CALLED: get_order_status(order_id='{order_id}') ---\")\n    mock_db = {\n        \"ORD12345\": {\"status\": \"Shipped\", \"estimated_delivery\": \"2024-03-15\", \"carrier\": \"ExpressPost\"},\n        \"ORD67890\": {\"status\": \"Processing\", \"estimated_delivery\": \"2024-03-18\", \"carrier\": \"Standard\"},\n        \"ORD11223\": {\"status\": \"Delivered\", \"estimated_delivery\": \"2024-03-10\", \"carrier\": \"Local Courier\"}\n    }\n    status_info = mock_db.get(order_id, {\"status\": \"Not Found\", \"error\": \"Invalid order ID.\"})\n    print(f\"--- MOCK FUNCTION RETURNED: {status_info} ---\")\n    return status_info\n\ndef find_product_info(product_name: str) -> dict:\n    \"\"\"MOCK FUNCTION: Simulates looking up product info.\"\"\"\n    print(f\"--- MOCK FUNCTION CALLED: find_product_info(product_name='{product_name}') ---\")\n    mock_catalog = {\n        \"photon blaster x1\": {\"price\": 199.99, \"availability\": \"In Stock\", \"features\": [\"Laser targeting\", \"Rechargeable battery\", \"Adjustable power levels\"]},\n        \"gravity boots\": {\"price\": 89.50, \"availability\": \"Ships in 3-5 days\", \"features\": [\"Magnetic soles\", \"Comfort fit\", \"Sizes S/M/L\"]},\n        \"warp drive repair kit\": {\"price\": 450.00, \"availability\": \"In Stock\", \"features\": [\"Universal compatibility\", \"Includes plasma wrench\", \"DIY instructions\"]}\n    }\n    found_product = None\n    for name, info in mock_catalog.items():\n        if product_name.lower() in name.lower():\n            found_product = info\n            break\n    if found_product:\n        result = found_product\n    else:\n        result = {\"availability\": \"Not Found\", \"error\": f\"Product '{product_name}' not found in catalog.\"}\n    print(f\"--- MOCK FUNCTION RETURNED: {result} ---\")\n    return result\n\nprint(\"Mock functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:27:02.541486Z","iopub.execute_input":"2025-04-11T01:27:02.541911Z","iopub.status.idle":"2025-04-11T01:27:02.551361Z","shell.execute_reply.started":"2025-04-11T01:27:02.541881Z","shell.execute_reply":"2025-04-11T01:27:02.549811Z"}},"outputs":[{"name":"stdout","text":"Mock functions defined.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"Map function names (for API schema) to actual Python functions.","metadata":{}},{"cell_type":"code","source":"available_functions = {\n    \"get_order_status\": get_order_status,\n    \"find_product_info\": find_product_info,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:05.474507Z","iopub.execute_input":"2025-04-11T01:43:05.474885Z","iopub.status.idle":"2025-04-11T01:43:05.479731Z","shell.execute_reply.started":"2025-04-11T01:43:05.474843Z","shell.execute_reply":"2025-04-11T01:43:05.478604Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"# 2. Capability Demo: Few-Shot Prompting (Establishing Agent Persona)\n\n\n* **Problem:** Ensuring the AI agent communicates with the desired brand voice and helpfulness, rather than as a generic AI.\n* **Gen AI Solution:** Providing example interactions (few shots) in the initial chat history guides the model's tone and style.\n\n\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Capability Demo: Few-Shot Prompting ---\")\nprint(\"Goal: Define the agent's helpful persona for 'GadgetGalaxy'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:17.026589Z","iopub.execute_input":"2025-04-11T01:43:17.026986Z","iopub.status.idle":"2025-04-11T01:43:17.032339Z","shell.execute_reply.started":"2025-04-11T01:43:17.026957Z","shell.execute_reply":"2025-04-11T01:43:17.031248Z"}},"outputs":[{"name":"stdout","text":"\n--- Capability Demo: Few-Shot Prompting ---\nGoal: Define the agent's helpful persona for 'GadgetGalaxy'.\n","output_type":"stream"}],"execution_count":59},{"cell_type":"markdown","source":"Define a list of dictionaries representing example user/agent turns. This history serves as the few-shot examples to prime the model's persona.","metadata":{}},{"cell_type":"code","source":"initial_chat_history = [\n    {\"role\": \"user\", \"parts\": [\"Hi there!\"]},\n    {\"role\": \"model\", \"parts\": [\"Hello! Welcome to GadgetGalaxy support. How can I help you today?\"]},\n    {\"role\": \"user\", \"parts\": [\"Do you sell gravity boots?\"]},\n    {\"role\": \"model\", \"parts\": [\"Yes, we do! Our Gravity Boots are quite popular. Would you like to know more about their features, price, or availability?\"]},\n    {\"role\": \"user\", \"parts\": [\"I want to check on my recent order.\"]},\n    {\"role\": \"model\", \"parts\": [\"I can certainly help with that! Could you please provide your order ID?\"]}\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:19.212192Z","iopub.execute_input":"2025-04-11T01:43:19.212534Z","iopub.status.idle":"2025-04-11T01:43:19.218219Z","shell.execute_reply.started":"2025-04-11T01:43:19.212509Z","shell.execute_reply":"2025-04-11T01:43:19.216979Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"Initialize a Gemini model instance to create the AI model object we will interact with.\n* **Note:** If the model name is invalid or API access fails, this will raise an error.","metadata":{}},{"cell_type":"code","source":"model_for_few_shot = genai.GenerativeModel('gemini-1.5-flash-latest')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:21.856782Z","iopub.execute_input":"2025-04-11T01:43:21.857408Z","iopub.status.idle":"2025-04-11T01:43:21.862997Z","shell.execute_reply.started":"2025-04-11T01:43:21.857355Z","shell.execute_reply":"2025-04-11T01:43:21.861618Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"**Start a chat session using the initial history to Primes the specific chat instance with the desired persona.**","metadata":{}},{"cell_type":"code","source":"chat_session_few_shot = model_for_few_shot.start_chat(history=initial_chat_history)\nprint(\"Chat session for few-shot demo initialized with persona history.\")\n\nprint(\"\\nTesting the persona with a new query...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:24.151982Z","iopub.execute_input":"2025-04-11T01:43:24.152383Z","iopub.status.idle":"2025-04-11T01:43:24.159691Z","shell.execute_reply.started":"2025-04-11T01:43:24.152354Z","shell.execute_reply":"2025-04-11T01:43:24.158407Z"}},"outputs":[{"name":"stdout","text":"Chat session for few-shot demo initialized with persona history.\n\nTesting the persona with a new query...\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"**Send a new message to test the persona.**","metadata":{}},{"cell_type":"code","source":"prompt1 = \"I need help with my Photon Blaster X1\"\nprint(f\"User: {prompt1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:26.551185Z","iopub.execute_input":"2025-04-11T01:43:26.551572Z","iopub.status.idle":"2025-04-11T01:43:26.557407Z","shell.execute_reply.started":"2025-04-11T01:43:26.551545Z","shell.execute_reply":"2025-04-11T01:43:26.556100Z"}},"outputs":[{"name":"stdout","text":"User: I need help with my Photon Blaster X1\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"**Get and print the model's response and Observe if the response follows the helpful, brand-aware style from the examples.**","metadata":{}},{"cell_type":"code","source":"response1 = chat_session_few_shot.send_message(prompt1)\nprint(f\"Agent (Few-Shot): {response1.text}\")\nprint(\"-\" * 30)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-11T01:43:28.351567Z","iopub.execute_input":"2025-04-11T01:43:28.351962Z","iopub.status.idle":"2025-04-11T01:43:29.238854Z","shell.execute_reply.started":"2025-04-11T01:43:28.351935Z","shell.execute_reply":"2025-04-11T01:43:29.237846Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Agent (Few-Shot): Okay, I can help with that. To best assist you, could you please tell me what issue you're experiencing with your Photon Blaster X1?  The more details you can provide (e.g., error messages, specific symptoms, what you've already tried), the better I can help you troubleshoot the problem.\n\n------------------------------\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"prompt2 = \"Tell me about your return policy.\"\nprint(f\"User: {prompt1}\")\nresponse2 = chat_session_few_shot.send_message(prompt2)\nprint(f\"Agent (Few-Shot): {response2.text}\")\nprint(\"-\" * 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:31.355974Z","iopub.execute_input":"2025-04-11T01:43:31.356300Z","iopub.status.idle":"2025-04-11T01:43:32.496747Z","shell.execute_reply.started":"2025-04-11T01:43:31.356276Z","shell.execute_reply":"2025-04-11T01:43:32.495631Z"}},"outputs":[{"name":"stdout","text":"User: I need help with my Photon Blaster X1\nAgent (Few-Shot): Our return policy allows for returns within 30 days of purchase for most items.  Items must be in their original packaging and in new, unused condition.  A few exceptions apply, such as opened software or consumables.  We do not accept returns on items damaged due to misuse.  For a full refund, the item must be returned in its original condition.  Shipping costs for returns are generally the responsibility of the customer, unless the return is due to our error.  Before returning an item, please contact our customer service department to obtain a Return Merchandise Authorization (RMA) number.  You can find more details on our website's \"Returns and Refunds\" page.\n\n--------------------\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"\n# 3. Capability Demo: Function Calling (Accessing External Tools)\n\n\n* **Problem:** Enabling the AI agent to access real-time, external information (like order status) or perform actions (like booking).\n* **Gen AI Solution:** Defining 'tools' (our Python functions) that the model can request to call when needed to fulfill a user's request.\n\n\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Capability Demo: Function Calling ---\")\nprint(\"Goal: Define and enable tools for fetching order status and product info.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:36.493342Z","iopub.execute_input":"2025-04-11T01:43:36.493950Z","iopub.status.idle":"2025-04-11T01:43:36.500334Z","shell.execute_reply.started":"2025-04-11T01:43:36.493901Z","shell.execute_reply":"2025-04-11T01:43:36.498992Z"}},"outputs":[{"name":"stdout","text":"\n--- Capability Demo: Function Calling ---\nGoal: Define and enable tools for fetching order status and product info.\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"**Define the structure (schema)** of the available tools for the API to tell the Gemini model about the functions: their names, purposes (description), and expected inputs (parameters).\nMap the function names defined in the tools schema to our actual Python functions. It Allows the code to execute the correct Python function when the model requests it by name.\n","metadata":{}},{"cell_type":"code","source":"tools_schema = [\n    { # Representing a single \"Tool\" implicitly containing function declarations\n        \"function_declarations\": [\n            {\n                \"name\": \"get_order_status\", # Must match a key in available_functions\n                \"description\": \"Retrieves the current status and estimated delivery for a given GadgetGalaxy order ID.\",\n                # Define parameters using OpenAPI schema format (as dictionaries)\n                \"parameters\": {\n                    \"type\": \"object\", # Use \"object\" for OpenAPI schema\n                    \"properties\": {\n                        \"order_id\": {\n                            \"type\": \"string\", # Use \"string\" for OpenAPI schema\n                            \"description\": \"The unique identifier for the customer's order (e.g., ORD12345).\"\n                        }\n                    },\n                    \"required\": [\"order_id\"]\n                }\n            },\n            {\n                \"name\": \"find_product_info\", # Must match a key in available_functions\n                \"description\": \"Looks up details about a specific GadgetGalaxy product, such as price, availability, and features.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"product_name\": {\n                            \"type\": \"string\",\n                            \"description\": \"The name of the product the customer is asking about (e.g., 'Photon Blaster X1', 'gravity boots'). Should be specific.\"\n                        }\n                    },\n                    \"required\": [\"product_name\"]\n                }\n            }\n        ]\n    }\n]\n# --- END OF CHANGE ---\n\n\nprint(\"Tool schema defined for Gemini API using dictionary format.\")\n\nmodel_with_tools = genai.GenerativeModel(\n    model_name='gemini-1.5-flash-latest', \n    tools=tools_schema \n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:38.896337Z","iopub.execute_input":"2025-04-11T01:43:38.896726Z","iopub.status.idle":"2025-04-11T01:43:38.904264Z","shell.execute_reply.started":"2025-04-11T01:43:38.896687Z","shell.execute_reply":"2025-04-11T01:43:38.903285Z"}},"outputs":[{"name":"stdout","text":"Tool schema defined for Gemini API using dictionary format.\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"\n\n","metadata":{}},{"cell_type":"markdown","source":"Start a new chat session with this tool-enabled model, using the persona history.\n# **Why:** Creates an interactive session that has both the desired persona and function-calling abilities.\n","metadata":{}},{"cell_type":"code","source":"\nchat_session_functions = model_with_tools.start_chat(\n    history=initial_chat_history,\n    enable_automatic_function_calling=False # Important: We will handle the calls\n)\nprint(\"Model and chat session with function calling capabilities initialized.\")\n\nprint(\"\\nTesting function call for order status...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:46.962177Z","iopub.execute_input":"2025-04-11T01:43:46.962566Z","iopub.status.idle":"2025-04-11T01:43:46.969463Z","shell.execute_reply.started":"2025-04-11T01:43:46.962540Z","shell.execute_reply":"2025-04-11T01:43:46.968286Z"}},"outputs":[{"name":"stdout","text":"Model and chat session with function calling capabilities initialized.\n\nTesting function call for order status...\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"# **What:** Send a prompt designed to trigger the 'get_order_status' function.\n","metadata":{}},{"cell_type":"code","source":"prompt_order = \"Can you tell me the status of my order ORD12345?\"\nprint(f\"User: {prompt_order}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:43:49.552319Z","iopub.execute_input":"2025-04-11T01:43:49.552703Z","iopub.status.idle":"2025-04-11T01:43:49.558781Z","shell.execute_reply.started":"2025-04-11T01:43:49.552675Z","shell.execute_reply":"2025-04-11T01:43:49.557384Z"}},"outputs":[{"name":"stdout","text":"User: Can you tell me the status of my order ORD12345?\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"# **What:** Check if the model responded by requesting a function call.\n# **Why:** This is the core logic for function calling interaction.\n","metadata":{}},{"cell_type":"code","source":"response_order = chat_session_functions.send_message(prompt_order)\n\n# --- REFINED Manual Function Calling Handling (for response_order) ---\nfunction_calls_to_process = []\nfinal_response_text = None\n\ntry:\n    # **What:** Safely access the parts of the *response_order*.\n    if response_order.candidates and response_order.candidates[0].content.parts:\n        print(\"--- Parsing response parts for function calls ---\")\n        for part in response_order.candidates[0].content.parts:\n            if hasattr(part, 'function_call') and part.function_call:\n                print(f\"--- Found function call part: {part.function_call.name} ---\")\n                function_calls_to_process.append(part.function_call)\nexcept Exception as e:\n    print(f\"Warning: Could not parse response parts for function calls - {e}\")\n    try:\n        final_response_text = response_order.text\n    except Exception:\n        final_response_text = \"(Error retrieving response text after parsing failure)\"\n\nif function_calls_to_process:\n    print(\"Agent is requesting to use a tool(s)...\")\n    fc_list = function_calls_to_process\n    function_results = []\n\n    for fc in fc_list:\n        function_name = fc.name\n        function_args = {key: value for key, value in fc.args.items()}\n        print(f\"   Tool: {function_name}, Arguments: {function_args}\")\n\n        # **IMPORTANT**: This relies on 'available_functions' being defined earlier.\n        if function_name in available_functions:\n            function_to_call = available_functions[function_name]\n            try:\n                function_response_data = function_to_call(**function_args)\n                function_results.append({\n                    \"function_response\": {\n                        \"name\": function_name,\n                        \"response\": function_response_data # Send the raw dictionary result\n                     }\n                })\n            except Exception as e:\n                 print(f\" Error executing function {function_name}: {e}\")\n                 function_results.append({\n                     \"function_response\": {\n                         \"name\": function_name,\n                         \"response\": {\"error\": f\"Failed to execute function {function_name}: {e}\"}\n                     }\n                 })\n        else:\n            print(f\" Error: Model requested an unknown function: {function_name}\")\n            function_results.append({\n                \"function_response\": {\n                    \"name\": function_name,\n                    \"response\": {\"error\": f\"Function '{function_name}' is not available.\"}\n                }\n            })\n\n    print(\"--- Sending function results back to Agent ---\")\n    response_after_tools = chat_session_functions.send_message(function_results)\n\n    try:\n        final_response_text = response_after_tools.text\n        print(f\"Agent (after tool use): {final_response_text}\")\n    except Exception as e:\n        print(f\"Warning: Could not get text from response after tool use - {e}\")\n\nelse:\n    # No function calls detected in response_order\n    try:\n        final_response_text = response_order.text\n        print(f\"Agent (responded directly): {final_response_text}\")\n    except Exception as e:\n        print(f\"Warning: Could not get text from response - {e}\")\n\nprint(\"-\" * 30)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:06:57.019199Z","iopub.execute_input":"2025-04-11T02:06:57.019628Z","iopub.status.idle":"2025-04-11T02:06:58.035935Z","shell.execute_reply.started":"2025-04-11T02:06:57.019595Z","shell.execute_reply":"2025-04-11T02:06:58.034829Z"}},"outputs":[{"name":"stdout","text":"--- Parsing response parts for function calls ---\n--- Found function call part: get_order_status ---\nAgent is requesting to use a tool(s)...\n   Tool: get_order_status, Arguments: {'order_id': 'ORD12345'}\n--- MOCK FUNCTION CALLED: get_order_status(order_id='ORD12345') ---\n--- MOCK FUNCTION RETURNED: {'status': 'Shipped', 'estimated_delivery': '2024-03-15', 'carrier': 'ExpressPost'} ---\n--- Sending function results back to Agent ---\nAgent (after tool use): Your order (ORD12345) has shipped via ExpressPost and is estimated to arrive on March 15, 2024.\n\n------------------------------\n","output_type":"stream"}],"execution_count":101},{"cell_type":"markdown","source":"**** Function Calling Test: Product Info****","metadata":{}},{"cell_type":"code","source":"# --- Function Calling Test: Product Info ---\nprint(\"\\nTesting function call for product info...\")\nprompt_product = \"How much are the gravity boots?\"\nprint(f\"User: {prompt_product}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:08:42.727357Z","iopub.execute_input":"2025-04-11T02:08:42.727798Z","iopub.status.idle":"2025-04-11T02:08:42.734169Z","shell.execute_reply.started":"2025-04-11T02:08:42.727768Z","shell.execute_reply":"2025-04-11T02:08:42.733041Z"}},"outputs":[{"name":"stdout","text":"\nTesting function call for product info...\nUser: How much are the gravity boots?\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"response_product = chat_session_functions.send_message(prompt_product)\n\n# --- REFINED Manual Function Calling Handling (for response_order) ---\nfunction_calls_to_process = []\nfinal_response_text = None\n\ntry:\n    # **What:** Safely access the parts of the *response_order*.\n    if response_product.candidates and response_product.candidates[0].content.parts:\n        print(\"--- Parsing response parts for function calls ---\")\n        for part in response_product.candidates[0].content.parts:\n            if hasattr(part, 'function_call') and part.function_call:\n                print(f\"--- Found function call part: {part.function_call.name} ---\")\n                function_calls_to_process.append(part.function_call)\nexcept Exception as e:\n    print(f\"Warning: Could not parse response parts for function calls - {e}\")\n    try:\n        final_response_text = response_product.text\n    except Exception:\n        final_response_text = \"(Error retrieving response text after parsing failure)\"\n\nif function_calls_to_process:\n    print(\"Agent is requesting to use a tool(s)...\")\n    fc_list = function_calls_to_process\n    function_results = []\n\n    for fc in fc_list:\n        function_name = fc.name\n        function_args = {key: value for key, value in fc.args.items()}\n        print(f\"   Tool: {function_name}, Arguments: {function_args}\")\n\n        # **IMPORTANT**: This relies on 'available_functions' being defined earlier.\n        if function_name in available_functions:\n            function_to_call = available_functions[function_name]\n            try:\n                function_response_data = function_to_call(**function_args)\n                function_results.append({\n                    \"function_response\": {\n                        \"name\": function_name,\n                        \"response\": function_response_data # Send the raw dictionary result\n                     }\n                })\n            except Exception as e:\n                 print(f\" Error executing function {function_name}: {e}\")\n                 function_results.append({\n                     \"function_response\": {\n                         \"name\": function_name,\n                         \"response\": {\"error\": f\"Failed to execute function {function_name}: {e}\"}\n                     }\n                 })\n        else:\n            print(f\" Error: Model requested an unknown function: {function_name}\")\n            function_results.append({\n                \"function_response\": {\n                    \"name\": function_name,\n                    \"response\": {\"error\": f\"Function '{function_name}' is not available.\"}\n                }\n            })\n\n    print(\"--- Sending function results back to Agent ---\")\n    response_after_tools = chat_session_functions.send_message(function_results)\n\n    try:\n        final_response_text = response_after_tools.text\n        print(f\"Agent (after tool use): {final_response_text}\")\n    except Exception as e:\n        print(f\"Warning: Could not get text from response after tool use - {e}\")\n\nelse:\n    # No function calls detected in response_order\n    try:\n        final_response_text = response_product.text\n        print(f\"Agent (responded directly): {final_response_text}\")\n    except Exception as e:\n        print(f\"Warning: Could not get text from response - {e}\")\n\nprint(\"-\" * 30)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:11:00.884417Z","iopub.execute_input":"2025-04-11T02:11:00.884903Z","iopub.status.idle":"2025-04-11T02:11:02.166612Z","shell.execute_reply.started":"2025-04-11T02:11:00.884853Z","shell.execute_reply":"2025-04-11T02:11:02.165563Z"}},"outputs":[{"name":"stdout","text":"--- Parsing response parts for function calls ---\n--- Found function call part: find_product_info ---\nAgent is requesting to use a tool(s)...\n   Tool: find_product_info, Arguments: {'product_name': 'gravity boots'}\n--- MOCK FUNCTION CALLED: find_product_info(product_name='gravity boots') ---\n--- MOCK FUNCTION RETURNED: {'price': 89.5, 'availability': 'Ships in 3-5 days', 'features': ['Magnetic soles', 'Comfort fit', 'Sizes S/M/L']} ---\n--- Sending function results back to Agent ---\nAgent (after tool use): The gravity boots are currently priced at $89.50 and will ship in 3-5 business days.  They feature magnetic soles, a comfort fit, and are available in sizes small, medium, and large.\n\n------------------------------\n","output_type":"stream"}],"execution_count":104},{"cell_type":"markdown","source":"#  4. Capability Demo: Structured Output (JSON Mode)\n#\n* **Problem Solved:** Getting structured, predictable data from the AI for automated processing (e.g., routing tickets, analytics).\n* **Gen AI Solution:** Instructing the model to output its response strictly in JSON format adhering to a specified schema.\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Capability Demo: Structured Output (JSON Mode) ---\")\nprint(\"Goal: Make the AI categorize a query and output the result as JSON.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:11:16.524415Z","iopub.execute_input":"2025-04-11T02:11:16.524797Z","iopub.status.idle":"2025-04-11T02:11:16.531086Z","shell.execute_reply.started":"2025-04-11T02:11:16.524770Z","shell.execute_reply":"2025-04-11T02:11:16.529806Z"}},"outputs":[{"name":"stdout","text":"\n--- Capability Demo: Structured Output (JSON Mode) ---\nGoal: Make the AI categorize a query and output the result as JSON.\n","output_type":"stream"}],"execution_count":105},{"cell_type":"markdown","source":"# **What:** Define a prompt that explicitly asks for JSON output with a specific structure.\n# **Why:** Guides the model to perform the analysis and format the result correctly.","metadata":{}},{"cell_type":"code","source":"json_prompt = \"\"\"\nAnalyze the customer query below. Respond ONLY with a valid JSON object containing these keys:\n- \"category\": (string) One of: \"Order Inquiry\", \"Product Question\", \"Return Request\", \"Technical Support\", \"General Feedback\", \"Other\"\n- \"keywords\": (list of strings) Key terms or product names mentioned.\n- \"urgency\": (string) One of: \"Low\", \"Medium\", \"High\".\n\nCustomer Query: \"Hi, my Photon Blaster X1 seems to be malfunctioning, it's making a weird buzzing sound. Can I return it or get it fixed? My order was ORD11223.\"\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:11:21.429743Z","iopub.execute_input":"2025-04-11T02:11:21.430178Z","iopub.status.idle":"2025-04-11T02:11:21.434967Z","shell.execute_reply.started":"2025-04-11T02:11:21.430147Z","shell.execute_reply":"2025-04-11T02:11:21.433573Z"}},"outputs":[],"execution_count":107},{"cell_type":"markdown","source":" **What:** Initialize a model specifically configured to output JSON.\n# **Why:** The `response_mime_type` setting enforces JSON output format.\n# **Note:** This will raise an error if the model name is invalid or API access fails.","metadata":{}},{"cell_type":"code","source":"model_json = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        response_mime_type=\"application/json\" # Force JSON output\n    )\n)\nprint(\"Model for JSON output initialized.\")\n\nprint(\"\\nSending prompt for JSON categorization...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:11:24.198657Z","iopub.execute_input":"2025-04-11T02:11:24.199009Z","iopub.status.idle":"2025-04-11T02:11:24.205388Z","shell.execute_reply.started":"2025-04-11T02:11:24.198984Z","shell.execute_reply":"2025-04-11T02:11:24.204133Z"}},"outputs":[{"name":"stdout","text":"Model for JSON output initialized.\n\nSending prompt for JSON categorization...\n","output_type":"stream"}],"execution_count":108},{"cell_type":"markdown","source":"# **What:** Generate content using the JSON-specific model and prompt.","metadata":{}},{"cell_type":"code","source":"response_json = model_json.generate_content(json_prompt)\n\nprint(\"\\nAgent (Raw JSON Output):\")\nprint(response_json.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:11:52.929621Z","iopub.execute_input":"2025-04-11T02:11:52.930037Z","iopub.status.idle":"2025-04-11T02:11:53.441194Z","shell.execute_reply.started":"2025-04-11T02:11:52.930009Z","shell.execute_reply":"2025-04-11T02:11:53.439985Z"}},"outputs":[{"name":"stdout","text":"\nAgent (Raw JSON Output):\n{\"category\": \"Return Request\", \"keywords\": [\"Photon Blaster X1\", \"buzzing sound\", \"ORD11223\"], \"urgency\": \"Medium\"}\n","output_type":"stream"}],"execution_count":110},{"cell_type":"markdown","source":"# **What:** Print the raw text output from the model (expected to be a JSON string).","metadata":{}},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T01:47:33.731924Z","iopub.execute_input":"2025-04-11T01:47:33.732302Z","iopub.status.idle":"2025-04-11T01:47:33.737603Z","shell.execute_reply.started":"2025-04-11T01:47:33.732274Z","shell.execute_reply":"2025-04-11T01:47:33.736346Z"}},"outputs":[{"name":"stdout","text":"{\"category\": \"Return Request\", \"keywords\": [\"Photon Blaster X1\", \"buzzing sound\", \"ORD11223\"], \"urgency\": \"Medium\"}\n","output_type":"stream"}],"execution_count":80},{"cell_type":"markdown","source":" **What:** Attempt to parse the JSON string.\n# **Why:** Verifies that the model returned valid JSON.","metadata":{}},{"cell_type":"code","source":"try:\n    parsed_json = json.loads(response_json.text)\n    print(\"\\nParsed JSON object (for verification):\")\n    print(json.dumps(parsed_json, indent=2)) # Pretty-print\n    print(\"\\n Successfully received and parsed structured JSON output.\")\nexcept json.JSONDecodeError as e:\n    # This try/except remains as it checks the *model's output*, not the setup.\n    print(f\"\\n Error: Model response was not valid JSON. {e}\")\n    print(f\"   Raw response received: {response_json.text}\")\nprint(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:12:19.684643Z","iopub.execute_input":"2025-04-11T02:12:19.685081Z","iopub.status.idle":"2025-04-11T02:12:19.693917Z","shell.execute_reply.started":"2025-04-11T02:12:19.685051Z","shell.execute_reply":"2025-04-11T02:12:19.692727Z"}},"outputs":[{"name":"stdout","text":"\nParsed JSON object (for verification):\n{\n  \"category\": \"Return Request\",\n  \"keywords\": [\n    \"Photon Blaster X1\",\n    \"buzzing sound\",\n    \"ORD11223\"\n  ],\n  \"urgency\": \"Medium\"\n}\n\n Successfully received and parsed structured JSON output.\n------------------------------\n","output_type":"stream"}],"execution_count":111},{"cell_type":"markdown","source":"#  5. Simple Interactive Agent Loop (Combining Persona & Function Calling)\n#\n# **What:** A basic loop demonstrating the agent interacting with a user, using its persona and function-calling abilities.\n# **Why:** Simulates a live chat session with the AI agent.\n# **Note:** This section will fail if `chat_session_functions` was not successfully created in step 3 (e.g., due to API key issues).\n#","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Starting Interactive Customer Support Agent ---\")\nprint(\"Using the agent with persona and function calling enabled.\")\nprint(\"Ask about products (e.g., 'Photon Blaster X1', 'gravity boots')\")\nprint(\"or check order status (e.g., 'ORD12345', 'ORD67890', 'ORD11223').\")\nprint(\"Type 'quit' to exit.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:12:27.339843Z","iopub.execute_input":"2025-04-11T02:12:27.340288Z","iopub.status.idle":"2025-04-11T02:12:27.346892Z","shell.execute_reply.started":"2025-04-11T02:12:27.340257Z","shell.execute_reply":"2025-04-11T02:12:27.345551Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Interactive Customer Support Agent ---\nUsing the agent with persona and function calling enabled.\nAsk about products (e.g., 'Photon Blaster X1', 'gravity boots')\nor check order status (e.g., 'ORD12345', 'ORD67890', 'ORD11223').\nType 'quit' to exit.\n","output_type":"stream"}],"execution_count":112},{"cell_type":"markdown","source":"# The loop starts directly, assuming chat_session_functions exists.\n","metadata":{}},{"cell_type":"code","source":"while True:\n    user_input = input(\"You: \")\n    if user_input.lower() == 'quit':\n        print(\"Agent: Thank you for contacting GadgetGalaxy support. Goodbye!\")\n        break\n    if not user_input:\n        continue\n\n   # print(\"--- Sending message to Agent ---\") # Debug print\n    initial_response = chat_session_functions.send_message(user_input)\n    \n    function_calls_to_process = []\n    final_response_text = None\n\n    try:\n        if initial_response.candidates and initial_response.candidates[0].content.parts:\n          #  print(\"--- Parsing response parts for function calls ---\")\n            for part in initial_response.candidates[0].content.parts:\n                if hasattr(part, 'function_call') and part.function_call:\n                    print(f\"--- Found function call part: {part.function_call.name} ---\")\n                    function_calls_to_process.append(part.function_call)\n    except Exception as e:\n        print(f\"Warning: Could not parse initial response parts for function calls - {e}\")\n        try:\n            final_response_text = initial_response.text\n        except Exception:\n            final_response_text = \"(Error retrieving response text after parsing failure)\"\n\n    if function_calls_to_process:\n      #  print(\"Agent is requesting to use a tool(s)...\")\n        fc_list = function_calls_to_process\n        function_results = []\n\n        for fc in fc_list:\n            function_name = fc.name\n            function_args = {key: value for key, value in fc.args.items()}\n            print(f\"   Tool: {function_name}, Arguments: {function_args}\")\n\n            if function_name in available_functions:\n                function_to_call = available_functions[function_name]\n                try:\n                    function_response_data = function_to_call(**function_args)\n                    function_results.append({\n                        \"function_response\": {\n                            \"name\": function_name,\n                            \"response\": function_response_data # Send the raw dictionary result\n                         }\n                    })\n                except Exception as e:\n                     print(f\" Error executing function {function_name}: {e}\")\n                     function_results.append({\n                         \"function_response\": {\n                             \"name\": function_name,\n                             \"response\": {\"error\": f\"Failed to execute function {function_name}: {e}\"}\n                         }\n                     })\n            else:\n                print(f\"Error: Model requested an unknown function: {function_name}\")\n                function_results.append({\n                    \"function_response\": {\n                        \"name\": function_name,\n                        \"response\": {\"error\": f\"Function '{function_name}' is not available.\"}\n                    }\n                })\n\n     #   print(\"--- Sending function results back to Agent ---\")\n        response_after_tools = interactive_chat.send_message(function_results)\n\n        try:\n            final_response_text = response_after_tools.text\n            print(f\"Agent: {final_response_text}\")\n        except Exception as e:\n            print(f\"Warning: Could not get text from response after tool use - {e}\")\n\n    else:\n        # No function calls detected in initial_response\n        try:\n            final_response_text = initial_response.text\n            print(f\"Agent : {final_response_text}\")\n        except Exception as e:\n            print(f\"Warning: Could not get text from initial response - {e}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T02:26:37.705654Z","iopub.execute_input":"2025-04-11T02:26:37.706065Z","iopub.status.idle":"2025-04-11T02:26:42.642502Z","shell.execute_reply.started":"2025-04-11T02:26:37.706036Z","shell.execute_reply":"2025-04-11T02:26:42.641355Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"You:  hi\n"},{"name":"stdout","text":"Agent : Hi there! Welcome to GadgetGalaxy support.  How can I help you today?\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  quit\n"},{"name":"stdout","text":"Agent: Thank you for contacting GadgetGalaxy support. Goodbye!\n","output_type":"stream"}],"execution_count":118}]}